{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUFtv+eimMdONDgz41vMnn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KO1pi5mqycfX","executionInfo":{"status":"ok","timestamp":1666226456935,"user_tz":300,"elapsed":16801,"user":{"displayName":"Jarod Peters","userId":"17481856514331319220"}},"outputId":"62f14720-4322-426b-96f2-a3aef8965a71"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connected to developer.download\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \r0% [Waiting for headers] [Waiting for headers]\r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers]\r                                                                        \rHit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to ppa.launchpad\r                                                                               \rIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to ppa.launchpad\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.1.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"DataFrameBasics\").getOrCreate()"],"metadata":{"id":"A-UJXINrzQtY","executionInfo":{"status":"ok","timestamp":1666226473081,"user_tz":300,"elapsed":5425,"user":{"displayName":"Jarod Peters","userId":"17481856514331319220"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Read in data from S3 Buckets\n","from pyspark import SparkFiles\n","url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_16/food.csv\"\n","spark.sparkContext.addFile(url)\n","df = spark.read.csv(SparkFiles.get(\"food.csv\"), sep=\",\", header=True)"],"metadata":{"id":"WmgMPCzy1m2q","executionInfo":{"status":"ok","timestamp":1666226499896,"user_tz":300,"elapsed":4926,"user":{"displayName":"Jarod Peters","userId":"17481856514331319220"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Print our schema\n","df.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0WHYGzx14hW","executionInfo":{"status":"ok","timestamp":1666226571341,"user_tz":300,"elapsed":164,"user":{"displayName":"Jarod Peters","userId":"17481856514331319220"}},"outputId":"b03d8e53-497e-41d1-df5d-755a193760dd"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- food: string (nullable = true)\n"," |-- price: string (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["# Import struct fields that we can use\n","from pyspark.sql.types import StructField, StringType, IntegerType, StructType"],"metadata":{"id":"JC8WuyUm2ClT","executionInfo":{"status":"ok","timestamp":1666226603556,"user_tz":300,"elapsed":148,"user":{"displayName":"Jarod Peters","userId":"17481856514331319220"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Next we need to create the list of struct fields\n","schema = [StructField(\"food\", StringType(), True), StructField(\"price\", IntegerType(), True),]\n","schema"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MkgmadRC2GCo","executionInfo":{"status":"ok","timestamp":1666226618416,"user_tz":300,"elapsed":143,"user":{"displayName":"Jarod Peters","userId":"17481856514331319220"}},"outputId":"f74e50e5-89aa-472e-b3ff-0f3a5738be3e"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[StructField(food,StringType,true), StructField(price,IntegerType,true)]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Pass in our fields\n","final = StructType(fields=schema)\n","final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KA2ubLED2KCj","executionInfo":{"status":"ok","timestamp":1666226633106,"user_tz":300,"elapsed":149,"user":{"displayName":"Jarod Peters","userId":"17481856514331319220"}},"outputId":"eba6bf71-47cd-40bd-d21f-7eaeeb23caf4"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StructType(List(StructField(food,StringType,true),StructField(price,IntegerType,true)))"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Read our data with our new schema\n","dataframe = spark.read.csv(SparkFiles.get(\"food.csv\"), schema=final, sep=\",\", header=True)\n","dataframe.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"em5RmXEv2KXX","executionInfo":{"status":"ok","timestamp":1666226641930,"user_tz":300,"elapsed":204,"user":{"displayName":"Jarod Peters","userId":"17481856514331319220"}},"outputId":"3af2fb95-7c62-4bd4-aa61-d153e426967a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- food: string (nullable = true)\n"," |-- price: integer (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["# Add new column\n","dataframe.withColumn('newprice', dataframe['price']).show()\n","# Update column name\n","dataframe.withColumnRenamed('price','newerprice').show()\n","# Double the price\n","dataframe.withColumn('doubleprice',dataframe['price']*2).show()\n","# Add a dollar to the price\n","dataframe.withColumn('add_one_dollar',dataframe['price']+1).show()\n","# Half the price\n","dataframe.withColumn('half_price',dataframe['price']/2).show()"],"metadata":{"id":"mseneB0h2STk","executionInfo":{"status":"ok","timestamp":1666226682034,"user_tz":300,"elapsed":1174,"user":{"displayName":"Jarod Peters","userId":"17481856514331319220"}},"outputId":"dceb1b7c-77d6-488d-864b-049485ab8e1e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+-----+--------+\n","|   food|price|newprice|\n","+-------+-----+--------+\n","|  pizza|    0|       0|\n","|  sushi|   12|      12|\n","|chinese|   10|      10|\n","+-------+-----+--------+\n","\n","+-------+----------+\n","|   food|newerprice|\n","+-------+----------+\n","|  pizza|         0|\n","|  sushi|        12|\n","|chinese|        10|\n","+-------+----------+\n","\n","+-------+-----+-----------+\n","|   food|price|doubleprice|\n","+-------+-----+-----------+\n","|  pizza|    0|          0|\n","|  sushi|   12|         24|\n","|chinese|   10|         20|\n","+-------+-----+-----------+\n","\n","+-------+-----+--------------+\n","|   food|price|add_one_dollar|\n","+-------+-----+--------------+\n","|  pizza|    0|             1|\n","|  sushi|   12|            13|\n","|chinese|   10|            11|\n","+-------+-----+--------------+\n","\n","+-------+-----+----------+\n","|   food|price|half_price|\n","+-------+-----+----------+\n","|  pizza|    0|       0.0|\n","|  sushi|   12|       6.0|\n","|chinese|   10|       5.0|\n","+-------+-----+----------+\n","\n"]}]}]}